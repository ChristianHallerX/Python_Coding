{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Missing Grade\n",
    "\n",
    "https://www.hackerrank.com/challenges/predict-missing-grade/problem\n",
    "\n",
    "Student grades for\n",
    "- English\n",
    "- Physics\n",
    "- Chemistry\n",
    "- Mathematics\n",
    "- Computer Science\n",
    "- Biology\n",
    "- Physical Education\n",
    "- Economics\n",
    "- Accountancy\n",
    "- Business Studies\n",
    "\n",
    "The grades are reported 1-8. \n",
    "\n",
    "Grade 1 is assigned to the top one-eighth of students who pass the course.\n",
    "\n",
    "Grade 2 is assigned to the next one-eighth of students who pass the course.\n",
    "\n",
    "...\n",
    "\n",
    "Grade 8 is assigned to the last one-eighth of students who pass the course.\n",
    "\n",
    "\n",
    "\n",
    "**Problem:** Maths grades are missing.\n",
    "\n",
    "**Goal:** Predict Maths grades.\n",
    "\n",
    "\n",
    "\n",
    "## Input Data\n",
    "\n",
    "First line: N = student samples\n",
    "\n",
    "All following lines are student samples\n",
    "\n",
    "A row/sample contains four subjects with grades and a serial.\n",
    "\n",
    "## Output Data\n",
    "Mathematics grades only.\n",
    "\n",
    "## Display File Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79465, {'Physics': 8, 'Chemistry': 7, 'PhysicalEducation': 3, 'English': 4, 'Mathematics': 6, 'serial': 195490}, {'Physics': 1, 'Chemistry': 1, 'PhysicalEducation': 1, 'English': 3, 'Mathematics': 3, 'serial': 190869}, {'Physics': 1, 'Chemistry': 2, 'PhysicalEducation': 2, 'English': 1, 'Mathematics': 2, 'serial': 3111}, {'Physics': 8, 'Chemistry': 7, 'PhysicalEducation': 6, 'English': 7, 'Mathematics': 7, 'serial': 47738}, {'Physics': 1, 'Chemistry': 1, 'PhysicalEducation': 1, 'English': 3, 'Mathematics': 2, 'serial': 85520}, {'Physics': 2, 'Chemistry': 1, 'Biology': 2, 'English': 4, 'Mathematics': 8, 'serial': 182318}, {'Physics': 3, 'Chemistry': 4, 'PhysicalEducation': 5, 'English': 5, 'Mathematics': 8, 'serial': 77482}, {'Accountancy': 2, 'BusinessStudies': 5, 'Economics': 3, 'English': 6, 'Mathematics': 7, 'serial': 152940}, {'Physics': 5, 'Chemistry': 6, 'Biology': 7, 'English': 3, 'Mathematics': 8, 'serial': 132620}, {'Accountancy': 2, 'BusinessStudies': 1, 'Economics': 1, 'English': 3, 'Mathematics': 2, 'serial': 179461}, {'Physics': 1, 'Chemistry': 2, 'Biology': 1, 'English': 2, 'Mathematics': 3, 'serial': 13372}, {'Physics': 5, 'Chemistry': 3, 'Biology': 4, 'English': 3, 'Mathematics': 4, 'serial': 16669}, {'Physics': 4, 'Chemistry': 4, 'PhysicalEducation': 1, 'English': 3, 'Mathematics': 6, 'serial': 109769}, {'Physics': 2, 'Chemistry': 5, 'PhysicalEducation': 8, 'English': 3, 'Mathematics': 4, 'serial': 146933}, {'Physics': 2, 'Chemistry': 2, 'Biology': 1, 'English': 1, 'Mathematics': 3, 'serial': 216414}, {'Physics': 5, 'Chemistry': 6, 'PhysicalEducation': 7, 'English': 5, 'Mathematics': 5, 'serial': 164385}, {'Accountancy': 1, 'BusinessStudies': 3, 'Economics': 2, 'English': 4, 'Mathematics': 2, 'serial': 71655}, {'Physics': 5, 'Chemistry': 6, 'ComputerScience': 5, 'English': 3, 'Mathematics': 7, 'serial': 99907}, {'Physics': 1, 'Chemistry': 1, 'PhysicalEducation': 2, 'English': 5, 'Mathematics': 2, 'serial': 52690}]\n"
     ]
    }
   ],
   "source": [
    "# Load TRAINING data from file\n",
    "\n",
    "import json\n",
    "training_data = []\n",
    "with open('Predict_Missing_Grade_training.json') as f:\n",
    "    for line in f:\n",
    "        training_data.append(json.loads(line))\n",
    "print(training_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69530, {'Physics': 2, 'Chemistry': 2, 'Biology': 1, 'English': 1, 'serial': 221375}, {'Physics': 3, 'Chemistry': 3, 'ComputerScience': 4, 'English': 4, 'serial': 150188}, {'Accountancy': 1, 'BusinessStudies': 1, 'Economics': 3, 'English': 1, 'serial': 12154}, {'Physics': 2, 'Chemistry': 2, 'ComputerScience': 2, 'English': 1, 'serial': 31442}, {'Accountancy': 5, 'BusinessStudies': 4, 'Economics': 3, 'English': 2, 'serial': 137253}, {'Physics': 3, 'Chemistry': 6, 'ComputerScience': 5, 'English': 3, 'serial': 167311}, {'Physics': 8, 'Chemistry': 5, 'PhysicalEducation': 1, 'English': 8, 'serial': 81796}, {'Accountancy': 3, 'BusinessStudies': 3, 'Economics': 2, 'English': 6, 'serial': 205967}, {'Physics': 3, 'Chemistry': 2, 'Biology': 1, 'English': 3, 'serial': 154440}, {'Physics': 3, 'Chemistry': 2, 'PhysicalEducation': 2, 'English': 4, 'serial': 98579}, {'Physics': 1, 'Chemistry': 1, 'ComputerScience': 1, 'English': 2, 'serial': 207309}, {'Physics': 1, 'Chemistry': 1, 'Biology': 4, 'English': 1, 'serial': 79043}, {'Physics': 1, 'Chemistry': 2, 'PhysicalEducation': 1, 'English': 1, 'serial': 61911}, {'Physics': 4, 'Chemistry': 4, 'Biology': 2, 'English': 3, 'serial': 129486}, {'Physics': 4, 'Chemistry': 4, 'ComputerScience': 4, 'English': 3, 'serial': 87638}, {'Physics': 5, 'Chemistry': 4, 'ComputerScience': 6, 'English': 3, 'serial': 208376}, {'Physics': 6, 'Chemistry': 5, 'PhysicalEducation': 2, 'English': 7, 'serial': 47463}, {'Physics': 1, 'Chemistry': 1, 'ComputerScience': 2, 'English': 1, 'serial': 90611}, {'Physics': 7, 'Chemistry': 8, 'ComputerScience': 7, 'English': 4, 'serial': 159154}]\n"
     ]
    }
   ],
   "source": [
    "# Load TESTING data from file\n",
    "testing_data = []\n",
    "with open('Predict_Missing_Grade_sample-test.in.json') as f:\n",
    "    for line in f:\n",
    "        testing_data.append(json.loads(line))\n",
    "print(testing_data[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Load TRAINING data from file\n",
    "training_data = []\n",
    "with open('Predict_Missing_Grade_training.json') as f:\n",
    "    for line in f:\n",
    "        training_data.append(json.loads(line))\n",
    "\n",
    "# Extract the unique features/subjects used for training\n",
    "unique_features = [x.keys() for x in training_data[1:]]\n",
    "unique_features = list(set(list(itertools.chain(*unique_features))))\n",
    "\n",
    "# maths and the serial are not used for training. Nine features remain\n",
    "unique_features.remove('Mathematics')\n",
    "unique_features.remove(\"serial\")\n",
    "\n",
    "# Give the unique features an ID. dicts with \"subject name : subject ID\" (training_set), \"subject ID : subject name\" (training_inverse_set)\n",
    "count = 0\n",
    "training_set = {}\n",
    "training_inverse_set = {}\n",
    "\n",
    "for i in unique_features:\n",
    "    training_set[i] = count\n",
    "    training_inverse_set[count] = i\n",
    "    count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract TRAINING features and classes    \n",
    "training_features = []\n",
    "training_class = []\n",
    "\n",
    "for row in training_data[1:]:\n",
    "    # list placeholder with nine values for the unique features. Zero remains if no grade in subject.\n",
    "    each_training = [0,0,0,0,0,0,0,0,0] \n",
    "    \n",
    "    for item in row:\n",
    "        \n",
    "        # extract maths grade as training class/label from row\n",
    "        if item == 'Mathematics':\n",
    "            training_class.append(row[item])\n",
    "            \n",
    "        # extract serial and discard\n",
    "        elif item == 'serial':\n",
    "            continue\n",
    "        \n",
    "        # extract all other subjects\n",
    "        else:\n",
    "            # use ID to place grade in list\n",
    "            each_training[training_set[item]] = row[item]\n",
    "            \n",
    "    training_features.append(each_training)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Load TESTING data from file\n",
    "testing_data = []\n",
    "with open('Predict_Missing_Grade_sample-test.in.json') as f:\n",
    "    for line in f:\n",
    "        testing_data.append(json.loads(line))\n",
    "\n",
    "# Extract TESTING features\n",
    "testing_features = []\n",
    "\n",
    "for row in testing_data[1:]:\n",
    "    # list placeholder with nine values for the unique features. Zero remains if no grade in subject.\n",
    "    each_testing = [0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # extract all other subjects, maths does not exist in the test set\n",
    "    for item in row:\n",
    "        \n",
    "        # extract serial and discard\n",
    "        if item == 'serial':\n",
    "            continue\n",
    "        \n",
    "        # extract all other subjects\n",
    "        else:\n",
    "            each_testing[training_set[item]] = row[item]\n",
    "            #each_testing[training_set[each_data]] = x[each_data]\n",
    "    \n",
    "    testing_features.append(each_testing)\n",
    "\n",
    "\n",
    "\n",
    "# TRAIN model\n",
    "model = SGDRegressor(penalty='l2',loss='squared_loss')\n",
    "model.fit(training_features, training_class)\n",
    "\n",
    "\n",
    "# PREDICT test labels\n",
    "prediction = model.predict(testing_features)\n",
    "\n",
    "# PRINT predictions\n",
    "for y_hat in prediction[:20]:\n",
    "    print(int(y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using stdin for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d3113f8d0885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# Load TESTING data via stdin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mtesting_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileinput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mtesting_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\fileinput.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filelineno\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\fileinput.py\u001b[0m in \u001b[0;36m_readline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_openhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m  \u001b[1;31m# hide FileInput._readline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "\n",
    "import json\n",
    "import fileinput\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Load TRAINING data from file\n",
    "training_data = []\n",
    "with open('Predict_Missing_Grade_training.json') as f:\n",
    "    for line in f:\n",
    "        training_data.append(json.loads(line))\n",
    "\n",
    "# Extract the unique features/subjects used for training\n",
    "unique_features = [x.keys() for x in training_data[1:]]\n",
    "unique_features = list(set(list(itertools.chain(*unique_features))))\n",
    "\n",
    "# maths and the serial are not used for training. Nine features remain\n",
    "unique_features.remove('Mathematics')\n",
    "unique_features.remove(\"serial\")\n",
    "\n",
    "# Give the unique features an ID. dicts with \"subject name : subject ID\" (training_set), \"subject ID : subject name\" (training_inverse_set)\n",
    "count = 0\n",
    "training_set = {}\n",
    "training_inverse_set = {}\n",
    "\n",
    "for i in unique_features:\n",
    "    training_set[i] = count\n",
    "    training_inverse_set[count] = i\n",
    "    count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract TRAINING features and classes    \n",
    "training_features = []\n",
    "training_class = []\n",
    "\n",
    "for row in training_data[1:]:\n",
    "    # list placeholder with nine values for the unique features. Zero remains if no grade in subject.\n",
    "    each_training = [0,0,0,0,0,0,0,0,0] \n",
    "    \n",
    "    for item in row:\n",
    "        \n",
    "        # extract maths grade as training class/label from row\n",
    "        if item == 'Mathematics':\n",
    "            training_class.append(row[item])\n",
    "            \n",
    "        # extract serial and discard\n",
    "        elif item == 'serial':\n",
    "            continue\n",
    "        \n",
    "        # extract all other subjects\n",
    "        else:\n",
    "            # use ID to place grade in list\n",
    "            each_training[training_set[item]] = row[item]\n",
    "            \n",
    "    training_features.append(each_training)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Load TESTING data via stdin\n",
    "testing_data = []\n",
    "for line in fileinput.input():\n",
    "        testing_data.append(json.loads(line))\n",
    "\n",
    "# Extract TESTING features\n",
    "testing_features = []\n",
    "\n",
    "for row in testing_data[1:]:\n",
    "    # list placeholder with nine values for the unique features. Zero remains if no grade in subject.\n",
    "    each_testing = [0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # extract all other subjects, maths does not exist in the test set\n",
    "    for item in row:\n",
    "        \n",
    "        # extract serial and discard\n",
    "        if item == 'serial':\n",
    "            continue\n",
    "        \n",
    "        # extract all other subjects\n",
    "        else:\n",
    "            each_testing[training_set[item]] = row[item]\n",
    "    \n",
    "    testing_features.append(each_testing)\n",
    "\n",
    "\n",
    "\n",
    "# TRAIN model\n",
    "model = SGDRegressor(penalty='l2',loss='squared_loss')\n",
    "model.fit(training_features, training_class)\n",
    "\n",
    "\n",
    "# PREDICT test labels\n",
    "prediction = model.predict(testing_features)\n",
    "\n",
    "# PRINT predictions\n",
    "for y_hat in prediction:\n",
    "    print(int(y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

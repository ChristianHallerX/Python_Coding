{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Exchange Question Classifier\n",
    "\n",
    "https://www.hackerrank.com/challenges/stack-exchange-question-classifier/problem\n",
    "\n",
    "## Input Data\n",
    "\n",
    "Questions from ten different topics (classes).\n",
    "\n",
    "The training JSON contains following strings:\n",
    "1. 'topic' (class)\n",
    "2. 'question' title\n",
    "3. 'excerpt' of question\n",
    "\n",
    "The test input txt file contains: \n",
    "1. 'question' title\n",
    "2. 'excerpt'\n",
    "\n",
    "The topic (class) of the test set has to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20219,\n",
       " {'topic': 'electronics',\n",
       "  'question': 'What is the effective differencial effective of this circuit',\n",
       "  'excerpt': \"I'm trying to work out, in general terms, the effective capacitance of this circuit (see diagram: http://i.stack.imgur.com/BS85b.png).  \\n\\nWhat is the effective capacitance of this circuit and will the ...\\r\\n        \"},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'Heat sensor with fan cooling',\n",
       "  'excerpt': 'Can I know which component senses heat or acts as heat sensor in the following circuit?\\nIn the given diagram, it is said that the 4148 diode acts as the sensor. But basically it is a zener diode and ...\\r\\n        '},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'Outlet Installation--more wires than my new outlet can use [on hold]',\n",
       "  'excerpt': 'I am replacing a wall outlet with a Cooper Wiring USB outlet (TR7745).  The new outlet has 3 wires coming out of it--a black, a white, and a green.  Each one needs to be attached with a wire nut to ...\\r\\n        '},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'Buck Converter Operation Question',\n",
       "  'excerpt': 'i have been reading about the buck converter, and have also referred to the various online resources like here.\\n\\n\\n\\nIn the above circuit, as I understand, when switch closes, current starts to increase ...\\r\\n        '},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'Urgent help in area of ASIC design, verification, SoC [on hold]',\n",
       "  'excerpt': \"I need help with deciding on a Master's Project and I need some ideas related to the field of ASIC Design/ verification or something related to SoC's, FPGA and or combination. I wish to pursue the ...\\r\\n        \"},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'Slowly supplying power to a very high load',\n",
       "  'excerpt': 'Is it possible to supply power to a very high load within a huge time range?\\n\\nThis question particularly regards MOSFETs.\\nI know that a MOSFET must switch fast so that a little power would develop ...\\r\\n        '},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'I have a 110 VAC solenoid and want to know what kind of circuit i should build to control it from my microcontroller?',\n",
       "  'excerpt': \"My solenoid is part of an old espresso machine, the circuit that detected low water level died and i can't replace it. I am adding a micro-controller to remotely turn it on and off and to control this ...\\r\\n        \"},\n",
       " {'topic': 'electronics',\n",
       "  'question': \"Can't read user-defined configuration space pci-express IP Virtex 6 Xilinx in testbench\",\n",
       "  'excerpt': 'I use IP core PCI-E for Virtex-6 v.2.5\\n\\nThere  is configuration space in PCI-E\\n\\nIt divides on standart space of PCI-E and vendor-specified or user-defined configuration space.\\n\\nThere are two types of ...\\r\\n        '},\n",
       " {'topic': 'electronics',\n",
       "  'question': 'Understanding specs of PNP transistor for replacement',\n",
       "  'excerpt': 'I want to replace an ON Semicondutor BC557 PNP transistor with a Multicomp BC557 PNP transistor. It is just for general switching of LEDs. But the specs look different although they are same mode. \\n\\n...\\r\\n        '}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train JSON\n",
    "import json\n",
    "\n",
    "training_data = []\n",
    "with open('Stack_Exchange_Question_Classifier_training.json','r',encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        training_data.append(json.loads(line))\n",
    "training_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21345\\n',\n",
       " '{\"question\":\"Are there any SciFi treatments of time travel that avoid the typical paradoxes? [duplicate]\",\"excerpt\":\"Possible Duplicate:\\\\n  Why do time-travel stories often have the characters “returning” to the future?  \\\\n\\\\n\\\\n\\\\n\\\\nThe possibility of time travel normally creates paradoxes. If you can travel into the ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"How to auto strip hyperlinks &amp; images in wordpress post\",\"excerpt\":\"I creat a post form on front-end for wordpress members by use DJD Site Post plugin.\\\\nPlugin url: http://wordpress.org/extend/plugins/djd-site-post/\\\\n\\\\nAnd now i want to auto strip all hyperlink &amp; ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"Why do fantasy writers depict pointy hats as the headgear of choice for Witches and Wizards?\",\"excerpt\":\"They don\\'t always wear a hat, but when they do, it\\'s pointy.\\\\n\\\\n\\\\nWhy do fantasy writers depict pointy hats as the headgear of choice for Witches and Wizards?\\\\n\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"Clip polygons with other polygons based on matching attributes\",\"excerpt\":\"I have two shapefiles, one which contains event locations and the the other of which represents regions where events take place.\\\\n\\\\n\\\\nEvents polygons with year and region_name attributes\\\\nRegions ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"switch_to_blog() performance considerations &amp; alternatives\",\"excerpt\":\"I\\'m currently in the conceptual phase for a multisite network.\\\\n\\\\nThe rough idea is: There are multiple networked sites and all publish posts for their own. The network admin is able to establish ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"Nikon in-camera vs lightroom jpg conversion [duplicate]\",\"excerpt\":\"I\\'m just getting started with Lightroom 4.  I\\'ve been shooting RAW + JPG using my Nikon D7000, but would like to just shoot RAW and then convert to JPG in Lightroom.  What\\'s the most efficient way to ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"Get only form elements in Contact Form 7\",\"excerpt\":\"I want to get only the form elements of a form when applying do_action() for a contact form. My plan is to include only the input fields from other form in a main contact form.\\\\n\\\\nFor example:\\\\nI have a ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"change shell in Solaris/SunOS for your user only wihtout access to /etc/passwd\",\"excerpt\":\"How do I set the shell in Solaris/SunOS for my user only, without access to /etc/passwd or any other su stuff?\\\\n\\\\nIt should thereafter work both for interactive ssh (1) and ssh when you send commands ...\\\\r\\\\n        \"}\\n',\n",
       " '{\"question\":\"Linux training setup\",\"excerpt\":\"I want to give a tutorial/training type seminar on Linux. I also want to demonstrate certain Linux specific software with audience participation (on their own machines).\\\\n\\\\nWhat is the best way to go ...\\\\r\\\\n        \"}\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test input\n",
    "with open('Stack_Exchange_Question_Classifier_input00.txt','r', encoding=\"utf8\") as fh:\n",
    "     testing_data = fh.readlines()\n",
    "testing_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using txt for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scifi\n",
      "wordpress\n",
      "scifi\n",
      "gis\n",
      "wordpress\n",
      "photo\n",
      "wordpress\n",
      "unix\n",
      "unix\n",
      "scifi\n",
      "wordpress\n",
      "security\n",
      "apple\n",
      "photo\n",
      "apple\n",
      "unix\n",
      "android\n",
      "gis\n",
      "electronics\n",
      "apple\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load TRAINING data from file\n",
    "training_data = []\n",
    "with open('Stack_Exchange_Question_Classifier_training.json','r',encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        training_data.append(json.loads(line))\n",
    "\n",
    "# extraction: question and excerpt strings get joined\n",
    "training_feature = [x['question'].lower() + \" \" + x['excerpt'].lower() for x in training_data[1:]]\n",
    "training_topics = [x['topic'] for x in training_data[1:]]\n",
    "\n",
    "\n",
    "\n",
    "# Load TESTING data from file\n",
    "with open('Stack_Exchange_Question_Classifier_input00.txt','r', encoding=\"utf8\") as fh:\n",
    "     testing_data = fh.readlines()\n",
    "\n",
    "# extraction: question and excerpt strings get joined\n",
    "i = -1\n",
    "testing_feature = []\n",
    "for line in testing_data:\n",
    "    if i == -1:\n",
    "        n_testsamples = int(line)\n",
    "        i += 1\n",
    "    else:\n",
    "        testing_feature.append(json.loads(line)['question'] + \" \" + json.loads(line)['excerpt'])\n",
    "\n",
    "\n",
    "# tokenize train features   \n",
    "max_range = 1\n",
    "vectorizer = TfidfVectorizer(max_df=1.0, ngram_range=(1,max_range),stop_words='english', use_idf='True')\n",
    "vec_training_feature = vectorizer.fit_transform(training_feature)\n",
    "\n",
    "# train model\n",
    "model = MultinomialNB()\n",
    "model.fit(vec_training_feature, training_topics)\n",
    "\n",
    "# tokenize test features\n",
    "vec_test_feature = vectorizer.transform(testing_feature)\n",
    "\n",
    "# predict with model\n",
    "prediction = model.predict(vec_test_feature)\n",
    "for y_hat in prediction[:20]:\n",
    "    print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using stdin for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fd066296cb18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mtesting_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileinput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mn_testsamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\fileinput.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filelineno\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\fileinput.py\u001b[0m in \u001b[0;36m_readline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_openhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m  \u001b[1;31m# hide FileInput._readline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "# Enter your code here. Read input from STDIN. Print output to STDOUT\n",
    "\n",
    "import fileinput\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load TRAINING data from file\n",
    "training_data = []\n",
    "with open('Stack_Exchange_Question_Classifier_training.json','r',encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        training_data.append(json.loads(line))\n",
    "\n",
    "# extraction: question and excerpt strings get joined\n",
    "training_feature = [x['question'].lower() + \" \" + x['excerpt'].lower() for x in training_data[1:]]\n",
    "training_topics = [x['topic'] for x in training_data[1:]]\n",
    "\n",
    "\n",
    "\n",
    "# Load TESTING data from stdin\n",
    "# extraction: question and excerpt strings get joined\n",
    "i = -1\n",
    "testing_feature = []\n",
    "for line in fileinput.input():\n",
    "    if i == -1:\n",
    "        n_testsamples = int(line)\n",
    "        i += 1\n",
    "    else:\n",
    "        testing_feature.append(json.loads(line)['question'] + \" \" + json.loads(line)['excerpt'])\n",
    "\n",
    "\n",
    "# tokenize train features   \n",
    "max_range = 1\n",
    "vectorizer = TfidfVectorizer(max_df=1.0, ngram_range=(1,max_range),stop_words='english', use_idf='True')\n",
    "vec_training_feature = vectorizer.fit_transform(training_feature)\n",
    "\n",
    "# train model\n",
    "model = MultinomialNB()\n",
    "model.fit(vec_training_feature, training_topics)\n",
    "\n",
    "# tokenize test features\n",
    "vec_test_feature = vectorizer.transform(testing_feature)\n",
    "\n",
    "# predict with model\n",
    "prediction = model.predict(vec_test_feature)\n",
    "for y_hat in prediction[:20]:\n",
    "    print(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
